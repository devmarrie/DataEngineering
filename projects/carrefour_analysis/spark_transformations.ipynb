{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./c4/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./c4/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/05/31 22:10:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('c4') \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductName,OriginalPrice,ApplicablePrice,Type,PercentageDiscount,Category\n",
      "Millbakers English Muffins 300g,132,132.00,FOOD,0,bakery\n",
      "Millbakers Queen Cupcakes 260g,99,99.00,FOOD,0,bakery\n",
      "Sweet Moment Lemon &amp; Poppy Muffin 6&#39;s 300g,180,180.00,FOOD,0,bakery\n",
      "Sweet Moment Chocchip Muffin 6&#39;s300g,180,180.00,FOOD,0,bakery\n",
      "Millbakers Queen Cupcakes 200g,84,84.00,FOOD,0,bakery\n",
      "Millbakers Family Madeira Cake 750g,236,236.00,FOOD,0,bakery\n",
      "Festive Milky White Bread 800G,127,127.00,FOOD,0,bakery\n",
      "Millbakers Standard Madeira Cake 500g,165,165.00,FOOD,0,bakery\n",
      "Joy Super Bakers Queen Cake 350g (12 Pieces),154,154.00,FOOD,0,bakery\n"
     ]
    }
   ],
   "source": [
    "!head data/bakery.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 data/bakery.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/bakery.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark dataframe by reading the same file\n",
    "df = spark.read.csv('data/bakery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "|                 _c0|          _c1|            _c2| _c3|               _c4|     _c5|\n",
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount|Category|\n",
      "|Millbakers Englis...|          132|         132.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Queen ...|           99|          99.00|FOOD|                 0|  bakery|\n",
      "|Sweet Moment Lemo...|          180|         180.00|FOOD|                 0|  bakery|\n",
      "|Sweet Moment Choc...|          180|         180.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Queen ...|           84|          84.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Family...|          236|         236.00|FOOD|                 0|  bakery|\n",
      "|Festive Milky Whi...|          127|         127.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Standa...|          165|         165.00|FOOD|                 0|  bakery|\n",
      "|Joy Super Bakers ...|          154|         154.00|FOOD|                 0|  bakery|\n",
      "|Festive Family Wh...|           96|          96.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Coconu...|           90|          90.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          185|         185.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Chocol...|          134|         134.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Double...|           90|          90.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Fruit ...|          165|         165.00|FOOD|                 0|  bakery|\n",
      "|Carrefour Les Mad...|         1399|        1399.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          185|         185.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Rich C...|          100|         100.00|FOOD|                 0|  bakery|\n",
      "|Joy Super Bakers ...|          150|         150.00|FOOD|                 0|  bakery|\n",
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount|Category|\n",
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "|Millbakers Englis...|          132|         132.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Queen ...|           99|          99.00|FOOD|                 0|  bakery|\n",
      "|Sweet Moment Lemo...|          180|         180.00|FOOD|                 0|  bakery|\n",
      "|Sweet Moment Choc...|          180|         180.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Queen ...|           84|          84.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Family...|          236|         236.00|FOOD|                 0|  bakery|\n",
      "|Festive Milky Whi...|          127|         127.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Standa...|          165|         165.00|FOOD|                 0|  bakery|\n",
      "|Joy Super Bakers ...|          154|         154.00|FOOD|                 0|  bakery|\n",
      "|Festive Family Wh...|           96|          96.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Coconu...|           90|          90.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          185|         185.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Chocol...|          134|         134.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Double...|           90|          90.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Fruit ...|          165|         165.00|FOOD|                 0|  bakery|\n",
      "|Carrefour Les Mad...|         1399|        1399.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          185|         185.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Rich C...|          100|         100.00|FOOD|                 0|  bakery|\n",
      "|Joy Super Bakers ...|          150|         150.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          195|         195.00|FOOD|                 0|  bakery|\n",
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We forgot the header\n",
    "df = spark.read \\\n",
    "     .option('header', 'true') \\\n",
    "     .csv('data/bakery.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ProductName', StringType(), True), StructField('OriginalPrice', StringType(), True), StructField('ApplicablePrice', StringType(), True), StructField('Type', StringType(), True), StructField('PercentageDiscount', StringType(), True), StructField('Category', StringType(), True)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the schema is correct (Spark always infers a csv file's schema as StringType for all the columns)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./c4/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./c4/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./c4/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./c4/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./c4/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./c4/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Define our own schema using pandas\n",
    "!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_pandas = pd.read_csv('data/bakery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductName            object\n",
       "OriginalPrice           int64\n",
       "ApplicablePrice       float64\n",
       "Type                   object\n",
       "PercentageDiscount      int64\n",
       "Category               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ProductName', StringType(), True), StructField('OriginalPrice', LongType(), True), StructField('ApplicablePrice', DoubleType(), True), StructField('Type', StringType(), True), StructField('PercentageDiscount', LongType(), True), StructField('Category', StringType(), True)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the pandas data frame to create a spark schema\n",
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType([\n",
    "            types.StructField('ProductName', types.StringType(), True), \n",
    "            types.StructField('OriginalPrice', types.LongType(), True), \n",
    "            types.StructField('ApplicablePrice', types.LongType(), True), \n",
    "            types.StructField('Type', types.StringType(), True), \n",
    "            types.StructField('PercentageDiscount', types.LongType(), True), \n",
    "            types.StructField('Category', types.StringType(), True)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ProductName', StringType(), True), StructField('OriginalPrice', LongType(), True), StructField('ApplicablePrice', LongType(), True), StructField('Type', StringType(), True), StructField('PercentageDiscount', LongType(), True), StructField('Category', StringType(), True)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reread the data with the schema\n",
    "df = spark.read \\\n",
    "     .option('header', 'true') \\\n",
    "     .schema(schema) \\\n",
    "     .csv('data/bakery.csv')\n",
    "\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a parquet file mode append to include all\n",
    "df.write.parquet('data/pq/all_foods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount| Category|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|Red Bull Energy D...|          920|           null|FOOD|                15|beverages|\n",
      "|Organic India Ori...|          799|           null|FOOD|                15|beverages|\n",
      "|Quencher Life Pre...|          299|           null|FOOD|                 0|beverages|\n",
      "|Mayers Natural Sp...|          103|           null|FOOD|                 0|beverages|\n",
      "|Carrefour Mineral...|          495|           null|FOOD|                 0|beverages|\n",
      "|Pick N Peel Orang...|          292|           null|FOOD|                13|beverages|\n",
      "|Kericho Gold Pure...|          335|           null|FOOD|                 0|beverages|\n",
      "|Quencher Life Pre...|          514|           null|FOOD|                 0|beverages|\n",
      "|   Coca Cola Soda 2L|          190|           null|FOOD|                 0|beverages|\n",
      "|Waba Mineral Wate...|          600|           null|FOOD|                 0|beverages|\n",
      "|Red Bull Energy D...|          227|           null|FOOD|                 0|beverages|\n",
      "|My Choice Drinkig...|          479|           null|FOOD|                 0|beverages|\n",
      "|Coca Cola Soda As...|          628|           null|FOOD|                 0|beverages|\n",
      "|You.C1000Isotonic...|          224|           null|FOOD|                 0|beverages|\n",
      "|Minute Maid Apple...|          138|           null|FOOD|                 0|beverages|\n",
      "|      Sprite Soda 2L|          190|           null|FOOD|                 0|beverages|\n",
      "|Ribena Concentrat...|          535|           null|FOOD|                 0|beverages|\n",
      "|Aquamist Sparklin...|          104|           null|FOOD|                20|beverages|\n",
      "|Fanta Blackcurran...|          190|           null|FOOD|                 0|beverages|\n",
      "|Fanta Orange soda 2L|          190|           null|FOOD|                 0|beverages|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('data/pq/all_foods')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the sql queries on the full data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
