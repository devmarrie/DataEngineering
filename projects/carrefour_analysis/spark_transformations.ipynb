{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./c4/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./c4/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('c4') \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductName,OriginalPrice,ApplicablePrice,Type,PercentageDiscount,Category\n",
      "Millbakers English Muffins 300g,132,132.00,FOOD,0,bakery\n",
      "Millbakers Queen Cupcakes 260g,99,99.00,FOOD,0,bakery\n",
      "Sweet Moment Lemon &amp; Poppy Muffin 6&#39;s 300g,180,180.00,FOOD,0,bakery\n",
      "Sweet Moment Chocchip Muffin 6&#39;s300g,180,180.00,FOOD,0,bakery\n",
      "Millbakers Queen Cupcakes 200g,84,84.00,FOOD,0,bakery\n",
      "Millbakers Family Madeira Cake 750g,236,236.00,FOOD,0,bakery\n",
      "Festive Milky White Bread 800G,127,127.00,FOOD,0,bakery\n",
      "Millbakers Standard Madeira Cake 500g,165,165.00,FOOD,0,bakery\n",
      "Joy Super Bakers Queen Cake 350g (12 Pieces),154,154.00,FOOD,0,bakery\n"
     ]
    }
   ],
   "source": [
    "!head data/bakery.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 data/bakery.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/bakery.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark dataframe by reading the same file\n",
    "df = spark.read.csv('data/bakery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "|                 _c0|          _c1|            _c2| _c3|               _c4|     _c5|\n",
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount|Category|\n",
      "|Millbakers Englis...|          132|         132.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Queen ...|           99|          99.00|FOOD|                 0|  bakery|\n",
      "|Sweet Moment Lemo...|          180|         180.00|FOOD|                 0|  bakery|\n",
      "|Sweet Moment Choc...|          180|         180.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Queen ...|           84|          84.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Family...|          236|         236.00|FOOD|                 0|  bakery|\n",
      "|Festive Milky Whi...|          127|         127.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Standa...|          165|         165.00|FOOD|                 0|  bakery|\n",
      "|Joy Super Bakers ...|          154|         154.00|FOOD|                 0|  bakery|\n",
      "|Festive Family Wh...|           96|          96.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Coconu...|           90|          90.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          185|         185.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Chocol...|          134|         134.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Double...|           90|          90.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Fruit ...|          165|         165.00|FOOD|                 0|  bakery|\n",
      "|Carrefour Les Mad...|         1399|        1399.00|FOOD|                 0|  bakery|\n",
      "|Festive Poundcake...|          185|         185.00|FOOD|                 0|  bakery|\n",
      "|Millbakers Rich C...|          100|         100.00|FOOD|                 0|  bakery|\n",
      "|Joy Super Bakers ...|          150|         150.00|FOOD|                 0|  bakery|\n",
      "+--------------------+-------------+---------------+----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount| Category|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|Red Bull Energy D...|          920|         782.00|FOOD|                15|beverages|\n",
      "|Organic India Ori...|          799|         679.00|FOOD|                15|beverages|\n",
      "|Quencher Life Pre...|          299|         299.00|FOOD|                 0|beverages|\n",
      "|Mayers Natural Sp...|          103|         103.00|FOOD|                 0|beverages|\n",
      "|Carrefour Mineral...|          495|         495.00|FOOD|                 0|beverages|\n",
      "|Pick N Peel Orang...|          292|         254.00|FOOD|                13|beverages|\n",
      "|Kericho Gold Pure...|          335|         335.00|FOOD|                 0|beverages|\n",
      "|Quencher Life Pre...|          514|         514.00|FOOD|                 0|beverages|\n",
      "|   Coca Cola Soda 2L|          190|         190.00|FOOD|                 0|beverages|\n",
      "|Waba Mineral Wate...|          600|         600.00|FOOD|                 0|beverages|\n",
      "|Red Bull Energy D...|          227|         227.00|FOOD|                 0|beverages|\n",
      "|My Choice Drinkig...|          479|         479.00|FOOD|                 0|beverages|\n",
      "|Coca Cola Soda As...|          628|         628.00|FOOD|                 0|beverages|\n",
      "|You.C1000Isotonic...|          224|         224.00|FOOD|                 0|beverages|\n",
      "|Minute Maid Apple...|          138|         138.00|FOOD|                 0|beverages|\n",
      "|      Sprite Soda 2L|          190|         190.00|FOOD|                 0|beverages|\n",
      "|Ribena Concentrat...|          535|         535.00|FOOD|                 0|beverages|\n",
      "|Aquamist Sparklin...|          104|          83.00|FOOD|                20|beverages|\n",
      "|Fanta Blackcurran...|          190|         190.00|FOOD|                 0|beverages|\n",
      "|Fanta Orange soda 2L|          190|         190.00|FOOD|                 0|beverages|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We forgot the header\n",
    "df = spark.read \\\n",
    "     .option('header', 'true') \\\n",
    "     .csv('data/beverages.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ProductName', StringType(), True), StructField('OriginalPrice', StringType(), True), StructField('ApplicablePrice', StringType(), True), StructField('Type', StringType(), True), StructField('PercentageDiscount', StringType(), True), StructField('Category', StringType(), True)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the schema is correct (Spark always infers a csv file's schema as StringType for all the columns)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./c4/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./c4/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./c4/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./c4/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./c4/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in ./c4/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Define our own schema using pandas\n",
    "!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_pandas = pd.read_csv('data/bakery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductName            object\n",
       "OriginalPrice           int64\n",
       "ApplicablePrice       float64\n",
       "Type                   object\n",
       "PercentageDiscount      int64\n",
       "Category               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o101.legacyInferArrayTypeFromFirstElement. Trace:\npy4j.Py4JException: Method legacyInferArrayTypeFromFirstElement([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# use the pandas data frame to create a spark schema\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_pandas\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mschema()\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(\n\u001b[1;32m   1444\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:363\u001b[0m, in \u001b[0;36mSparkConversionMixin.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    362\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_from_pandas(data, schema, timezone)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/session.py:1485\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1483\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1485\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/session.py:1093\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m-> 1093\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchemaFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[1;32m   1095\u001b[0m     tupled_data: Iterable[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(converter, data)\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/session.py:953\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[1;32m    949\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_EMPTY_SCHEMA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    950\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    951\u001b[0m     )\n\u001b[1;32m    952\u001b[0m infer_dict_as_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39minferDictAsStruct()\n\u001b[0;32m--> 953\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacyInferArrayTypeFromFirstElement\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[1;32m    955\u001b[0m schema \u001b[38;5;241m=\u001b[39m reduce(\n\u001b[1;32m    956\u001b[0m     _merge_type,\n\u001b[1;32m    957\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m     ),\n\u001b[1;32m    967\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/py4j/protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o101.legacyInferArrayTypeFromFirstElement. Trace:\npy4j.Py4JException: Method legacyInferArrayTypeFromFirstElement([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n"
     ]
    }
   ],
   "source": [
    "# use the pandas data frame to create a spark schema\n",
    "spark.createDataFrame(df_pandas).schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType([\n",
    "            types.StructField('ProductName', types.StringType(), True), \n",
    "            types.StructField('OriginalPrice', types.LongType(), True), \n",
    "            types.StructField('ApplicablePrice', types.DoubleType(), True), \n",
    "            types.StructField('Type', types.StringType(), True), \n",
    "            types.StructField('PercentageDiscount', types.LongType(), True), \n",
    "            types.StructField('Category', types.StringType(), True)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ProductName', StringType(), True), StructField('OriginalPrice', LongType(), True), StructField('ApplicablePrice', DoubleType(), True), StructField('Type', StringType(), True), StructField('PercentageDiscount', LongType(), True), StructField('Category', StringType(), True)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reread the data with the schema\n",
    "df = spark.read \\\n",
    "     .option('header', 'true') \\\n",
    "     .schema(schema) \\\n",
    "     .csv('data/bakery.csv')\n",
    "\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/home/devmarrie/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/data/pq/all_foods already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# write to a parquet file mode append to include all\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/pq/all_foods\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/home/devmarrie/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/data/pq/all_foods already exists."
     ]
    }
   ],
   "source": [
    "# write to a parquet file mode append to include all\n",
    "df.write.parquet('data/pq/all_foods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount| Category|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|Red Bull Energy D...|          920|          782.0|FOOD|                15|beverages|\n",
      "|Organic India Ori...|          799|          679.0|FOOD|                15|beverages|\n",
      "|Quencher Life Pre...|          299|          299.0|FOOD|                 0|beverages|\n",
      "|Mayers Natural Sp...|          103|          103.0|FOOD|                 0|beverages|\n",
      "|Carrefour Mineral...|          495|          495.0|FOOD|                 0|beverages|\n",
      "|Pick N Peel Orang...|          292|          254.0|FOOD|                13|beverages|\n",
      "|Kericho Gold Pure...|          335|          335.0|FOOD|                 0|beverages|\n",
      "|Quencher Life Pre...|          514|          514.0|FOOD|                 0|beverages|\n",
      "|   Coca Cola Soda 2L|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Waba Mineral Wate...|          600|          600.0|FOOD|                 0|beverages|\n",
      "|Red Bull Energy D...|          227|          227.0|FOOD|                 0|beverages|\n",
      "|My Choice Drinkig...|          479|          479.0|FOOD|                 0|beverages|\n",
      "|Coca Cola Soda As...|          628|          628.0|FOOD|                 0|beverages|\n",
      "|You.C1000Isotonic...|          224|          224.0|FOOD|                 0|beverages|\n",
      "|Minute Maid Apple...|          138|          138.0|FOOD|                 0|beverages|\n",
      "|      Sprite Soda 2L|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Ribena Concentrat...|          535|          535.0|FOOD|                 0|beverages|\n",
      "|Aquamist Sparklin...|          104|           83.0|FOOD|                20|beverages|\n",
      "|Fanta Blackcurran...|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Fanta Orange soda 2L|          190|          190.0|FOOD|                 0|beverages|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('data/pq/all_foods')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the sql queries on the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount| Category|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|Red Bull Energy D...|          920|          782.0|FOOD|                15|beverages|\n",
      "|Organic India Ori...|          799|          679.0|FOOD|                15|beverages|\n",
      "|Quencher Life Pre...|          299|          299.0|FOOD|                 0|beverages|\n",
      "|Mayers Natural Sp...|          103|          103.0|FOOD|                 0|beverages|\n",
      "|Carrefour Mineral...|          495|          495.0|FOOD|                 0|beverages|\n",
      "|Pick N Peel Orang...|          292|          254.0|FOOD|                13|beverages|\n",
      "|Kericho Gold Pure...|          335|          335.0|FOOD|                 0|beverages|\n",
      "|Quencher Life Pre...|          514|          514.0|FOOD|                 0|beverages|\n",
      "|   Coca Cola Soda 2L|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Waba Mineral Wate...|          600|          600.0|FOOD|                 0|beverages|\n",
      "|Red Bull Energy D...|          227|          227.0|FOOD|                 0|beverages|\n",
      "|My Choice Drinkig...|          479|          479.0|FOOD|                 0|beverages|\n",
      "|Coca Cola Soda As...|          628|          628.0|FOOD|                 0|beverages|\n",
      "|You.C1000Isotonic...|          224|          224.0|FOOD|                 0|beverages|\n",
      "|Minute Maid Apple...|          138|          138.0|FOOD|                 0|beverages|\n",
      "|      Sprite Soda 2L|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Ribena Concentrat...|          535|          535.0|FOOD|                 0|beverages|\n",
      "|Aquamist Sparklin...|          104|           83.0|FOOD|                20|beverages|\n",
      "|Fanta Blackcurran...|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Fanta Orange soda 2L|          190|          190.0|FOOD|                 0|beverages|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pq = spark.read.parquet('data/pq/all_foods')\n",
    "df_pq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|      Category|   AverageDiscount|\n",
      "+--------------+------------------+\n",
      "|     beverages|1.3629032258064515|\n",
      "|fruits_n_veges|1.4074074074074074|\n",
      "|        frozen|2.2713178294573644|\n",
      "|    fresh_food|             1.958|\n",
      "|        bakery| 0.623015873015873|\n",
      "| food_cupboard|0.9447779111644657|\n",
      "| bio_n_organic|0.4816326530612245|\n",
      "+--------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What is the average discount for each product category?\n",
    "avg_discount = df_pq.groupBy('Category').agg({\"PercentageDiscount\": \"avg\"}).withColumnRenamed(\"avg(PercentageDiscount)\", \"AverageDiscount\")\n",
    "avg_discount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o136.pandasStructHandlingMode. Trace:\npy4j.Py4JException: Method pandasStructHandlingMode([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the average discount\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m avg_df \u001b[38;5;241m=\u001b[39m \u001b[43mavg_discount\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:212\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pdf\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    211\u001b[0m     timezone \u001b[38;5;241m=\u001b[39m jconf\u001b[38;5;241m.\u001b[39msessionLocalTimeZone()\n\u001b[0;32m--> 212\u001b[0m     struct_in_pandas \u001b[38;5;241m=\u001b[39m \u001b[43mjconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandasStructHandlingMode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m    215\u001b[0m         [\n\u001b[1;32m    216\u001b[0m             _create_converter_to_pandas(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/Desktop/coding/DE_learning/DataEngineering/projects/carrefour_analysis/c4/lib/python3.10/site-packages/py4j/protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o136.pandasStructHandlingMode. Trace:\npy4j.Py4JException: Method pandasStructHandlingMode([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n"
     ]
    }
   ],
   "source": [
    "# Plot the average discount\n",
    "avg_df = avg_discount.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|      Category|TotalDiscountValue|\n",
      "+--------------+------------------+\n",
      "|     beverages|            6315.0|\n",
      "|fruits_n_veges| 7000.500000000002|\n",
      "|        frozen|            7547.0|\n",
      "|    fresh_food|         397407.35|\n",
      "|        bakery|2665.1000000000004|\n",
      "| food_cupboard|           16394.0|\n",
      "| bio_n_organic|            2180.0|\n",
      "+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the total value of discounts provided in each category?\n",
    "from pyspark.sql.functions import col\n",
    "sum_discount_value = df_pq.withColumn(\"DiscountValue\", col('OriginalPrice') - col('ApplicablePrice')) \\\n",
    "                          .groupBy('Category') \\\n",
    "                          .sum(\"DiscountValue\") \\\n",
    "                          .withColumnRenamed(\"sum(DiscountValue)\", \"TotalDiscountValue\")\n",
    "                          \n",
    "sum_discount_value.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+----------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount|  Category|\n",
      "+--------------------+-------------+---------------+----+------------------+----------+\n",
      "|Carrefour Frozen ...|          414|          100.0|FOOD|                76|    frozen|\n",
      "|Carrefour Frozen ...|          414|          100.0|FOOD|                76|    frozen|\n",
      "|Carrefour Frozen ...|         2499|         1000.0|FOOD|                60|    frozen|\n",
      "|South African  Be...|         3199|          649.5|FOOD|                59|fresh_food|\n",
      "|South African  Be...|         4699|          999.5|FOOD|                57|fresh_food|\n",
      "|Carrefour Frozen ...|          635|          300.0|FOOD|                53|    frozen|\n",
      "|Carrefour Frozen ...|         1219|          600.0|FOOD|                51|    frozen|\n",
      "|QUORN SOUTHERN ST...|          595|          298.0|FOOD|                50|    frozen|\n",
      "|Star Soda Soft Dr...|          140|           70.0|FOOD|                50| beverages|\n",
      "|   QUORN PIECES 300G|          595|          298.0|FOOD|                50|    frozen|\n",
      "+--------------------+-------------+---------------+----+------------------+----------+\n",
      "\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount| Category|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "|Red Bull Energy D...|          227|          227.0|FOOD|                 0|beverages|\n",
      "|Mt. Kenya Natural...|          519|          519.0|FOOD|                 0|beverages|\n",
      "|My Choice Drinkig...|          479|          479.0|FOOD|                 0|beverages|\n",
      "|Quencher Life Pre...|          299|          299.0|FOOD|                 0|beverages|\n",
      "|Coca Cola Soda As...|          628|          628.0|FOOD|                 0|beverages|\n",
      "|Mayers Natural Sp...|          103|          103.0|FOOD|                 0|beverages|\n",
      "|You.C1000Isotonic...|          224|          224.0|FOOD|                 0|beverages|\n",
      "|Kericho Gold Pure...|          335|          335.0|FOOD|                 0|beverages|\n",
      "|Fanta Blackcurran...|          190|          190.0|FOOD|                 0|beverages|\n",
      "|Minute Maid Apple...|          138|          138.0|FOOD|                 0|beverages|\n",
      "+--------------------+-------------+---------------+----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which products have the highest and lowest discounts?\n",
    "\n",
    "highest_discounted_product = df_pq.orderBy(col(\"PercentageDiscount\").desc()).limit(10)\n",
    "\n",
    "lowest_discounted_product = df_pq.orderBy(col(\"PercentageDiscount\").asc()).limit(10)\n",
    "\n",
    "highest_discounted_product.show()\n",
    "lowest_discounted_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+------------------+------------------+\n",
      "|      Category|MinPrice|MaxPrice|          AvgPrice|       StddevPrice|\n",
      "+--------------+--------+--------+------------------+------------------+\n",
      "|     beverages|    10.0|  2450.0| 356.3637992831541| 405.5670849027246|\n",
      "|fruits_n_veges|    18.0|  1538.0|  259.425925925926| 289.8139449620126|\n",
      "|        frozen|    29.0|  2580.0|467.28682170542635| 372.3043672487805|\n",
      "|    fresh_food|    20.0|  8980.0|         533.55965| 843.2890272901251|\n",
      "|        bakery|    25.0|  1899.0|211.64246031746035|295.26648882830983|\n",
      "| food_cupboard|     6.0| 10132.0|479.05402160864344| 786.7660366061849|\n",
      "| bio_n_organic|    25.0|  5000.0|  534.804081632653|  588.491718244436|\n",
      "+--------------+--------+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the distribution of product prices across categories?\n",
    "from pyspark.sql.functions import min, max, avg, stddev\n",
    "\n",
    "price_distribution = df_pq.groupBy(\"Category\").agg(\n",
    "    min(\"ApplicablePrice\").alias(\"MinPrice\"),\n",
    "    max(\"ApplicablePrice\").alias(\"MaxPrice\"),\n",
    "    avg(\"ApplicablePrice\").alias(\"AvgPrice\"),\n",
    "    stddev(\"ApplicablePrice\").alias(\"StddevPrice\")\n",
    ")\n",
    "\n",
    "price_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      Category|count|\n",
      "+--------------+-----+\n",
      "|     beverages|  103|\n",
      "|fruits_n_veges|    3|\n",
      "|        frozen|   27|\n",
      "|    fresh_food|   79|\n",
      "|        bakery|    5|\n",
      "| food_cupboard|   46|\n",
      "| bio_n_organic|    7|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many products have a discount applied per category? \n",
    "discounted_products_count = df_pq.filter(col(\"PercentageDiscount\") > 0) \\\n",
    "                                 .groupBy(\"Category\") \\\n",
    "                                 .count()\n",
    "discounted_products_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+----+------------------+-------------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount|     Category|\n",
      "+--------------------+-------------+---------------+----+------------------+-------------+\n",
      "|Elianto Corn Oil 20L|        10132|        10132.0|FOOD|                 0|food_cupboard|\n",
      "|       Salmon Steak |         4490|         8980.0|FOOD|                 0|   fresh_food|\n",
      "|Fresh Goat Carcas...|        13999|         8888.0|FOOD|                37|   fresh_food|\n",
      "|Fresh Lamb Carcas...|        13999|         8888.0|FOOD|                37|   fresh_food|\n",
      "|  Fresh Salmon Whole|         4199|         8398.0|FOOD|                 0|   fresh_food|\n",
      "| Halal Turkey Salami|         8050|         8050.0|FOOD|                 0|   fresh_food|\n",
      "|  Fresh Goat Carcass|          999|         7480.0|FOOD|                25|   fresh_food|\n",
      "|       Extra Chorizo|         7400|         7400.0|FOOD|                 0|   fresh_food|\n",
      "|Rina Vegetable Co...|         6756|         6756.0|FOOD|                 0|food_cupboard|\n",
      "|Casademont Choriz...|         6548|         6548.0|FOOD|                 0|   fresh_food|\n",
      "+--------------------+-------------+---------------+----+------------------+-------------+\n",
      "\n",
      "+--------------------+-------------+---------------+----+------------------+-------------+\n",
      "|         ProductName|OriginalPrice|ApplicablePrice|Type|PercentageDiscount|     Category|\n",
      "+--------------------+-------------+---------------+----+------------------+-------------+\n",
      "|Simba Mbili Curry...|            6|            6.0|FOOD|                 0|food_cupboard|\n",
      "|Kensalt Table Sal...|            9|            9.0|FOOD|                 0|food_cupboard|\n",
      "|Nescafe Classic I...|           10|           10.0|FOOD|                 0|    beverages|\n",
      "|Dormans Supreme F...|           10|           10.0|FOOD|                 0|    beverages|\n",
      "|Maccoffee Classic...|           10|           10.0|FOOD|                 0|    beverages|\n",
      "|Gibsons Instant C...|           10|           10.0|FOOD|                 0|    beverages|\n",
      "|Dormans Supreme G...|           12|           12.0|FOOD|                 0|    beverages|\n",
      "|Twisco chocolate ...|           13|           13.0|FOOD|                 0|    beverages|\n",
      "|Tropical Heat Gro...|           15|           15.0|FOOD|                 0|food_cupboard|\n",
      "|Clovers Pure Gluc...|           17|           17.0|FOOD|                 0|    beverages|\n",
      "+--------------------+-------------+---------------+----+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most expensive and cheapest product on Carrefour that day\n",
    "\n",
    "top_expensive_products = df_pq.orderBy(col(\"ApplicablePrice\").desc()).limit(10)\n",
    "\n",
    "top_cheap_products = df_pq.orderBy(col(\"ApplicablePrice\").asc()).limit(10)\n",
    "\n",
    "top_expensive_products.show()\n",
    "top_cheap_products.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
